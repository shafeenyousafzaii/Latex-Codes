\documentclass[12pt]{article}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}

\title{Day 2}
\author{Muhammad Shafeen}
\date{July 15-16, 2024}

\begin{document}

\maketitle

\section*{Setting Up Custom LLMs Using Google's MediaPipe}
On the second day, we followed Google's MediaPipe framework to set up custom Language Models (LLMs) for running offline on our phone. The setup process involved using Android Studio for the implementation and Google Colab for training the model, utilizing the Gamma model as the base.

\subsection*{Setup and Training}
\begin{itemize}
    \item \textbf{Android Studio:} We used Android Studio to set up the environment for our custom LLMs, ensuring compatibility with mobile devices.
    \item \textbf{Google Colab:} The training of the model was performed on Google Colab, leveraging its computational power to handle the complex training processes efficiently.
    \item \textbf{Gamma Model:} The Gamma model was employed due to its robustness and adaptability for our specific needs.
\end{itemize}

\subsection*{Challenges and Optimization Needs}
Despite successfully setting up the custom LLMs, we observed that the model's size made it slow on older phones. This indicated a need for further optimization to enhance performance on a broader range of devices.

\section*{Conclusion}
The first two days of the project involved significant steps towards setting up our offline model for Kargil and developing custom LLMs using Google's MediaPipe. While the initial setup is complete, ongoing optimization is required to improve the model's efficiency, especially on older mobile devices.

\end{document}
